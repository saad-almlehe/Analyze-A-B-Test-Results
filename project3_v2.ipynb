{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Conclusions](#conclusions)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "In this project I will analyze the result of an A/B test run by an e-commerce website. I will try to help the company to understand if they should implement the new page, keep the old page or run the experiment longer to make their decision.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will import these libraries that will help me in this project:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, i will read in the `ab_data.csv` data. then Store it in `df`. \n",
    "\n",
    "a. Read in the dataset and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "\n",
    "# see the first the 5 rows to explore data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - I can see we are dealing with categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# I used the info method to see the columns type , how many rows there and if there are missing values.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - we have 294478 rows and there are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this method will return the number of rows with unique user id :\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - the number of unique users in the dataset is 290584."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converted_proprtion = (rows that converted ) / (all rows)\n",
    "converted_proprtion = df[df['converted'] == 1]['user_id'].count() / df['user_id'].count()\n",
    "\n",
    "converted_proprtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -The proportion of users converted 0.1196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_page is data frame that contain all new page rows\n",
    "new_page = df[df['landing_page'] == 'new_page']\n",
    "\n",
    "# treatment is data frame that contain all treatment rows\n",
    "treatment = df[df['group'] == 'treatment']\n",
    "\n",
    "# here I filtered  new_page so it contains only control rows without treatment\n",
    "new_page = new_page[new_page['group'] != 'treatment']['user_id'].count()\n",
    "\n",
    "# here i filtered  treatment so it contains only old_page rows without new_page\n",
    "treatment = treatment[treatment['landing_page'] != 'new_page']['user_id'].count()\n",
    "\n",
    "# add them to know how many times new_page and treatment don’t match\n",
    "new_page + treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - The number of times the `new_page` and `treatment` don't match is 3893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# lets check agian : \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - we have no  missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page. \n",
    "\n",
    "a. Now I will create a new dataset that meets the specifications treatment match with new_page and control matsh with old_page \n",
    "then Store new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I will copy df into df2 to avoid slicing warnings form Jupyter \n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I filtered the df2 to contain  treatment and new_page row or control and old_page so we ignore rows that don’t match.\n",
    "df2 = df2[(df['group'] == 'treatment') & (df2['landing_page'] == 'new_page') | (df2['group'] == 'control') & (df2['landing_page'] == 'old_page')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - we got zero so it seems that it works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Using **df2** to answer below questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this method will return the number of rows with unique user id :\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - there are 290584 unique **user_id**s are in **df2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this data frame will take the one row that duplicated method return it as true:\n",
    "duplicated_user_id = df2[df2['user_id'].duplicated()]\n",
    "duplicated_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " -  (user_id = 773192 , group = treatment , landing_page = new_page , converted = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, timestamp, group, landing_page, converted]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this method will drop the row with index 2893 (the duplicated row in our data)\n",
    "df2.drop(index=2893 , inplace=True)\n",
    "\n",
    "# here I will check to make sure\n",
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use **df2** in the cells below \n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will take the sum of converted  (true ones) and divide it by the total number of converted\n",
    "prob_converting = df['converted'].sum() / df['converted'].count() \n",
    "prob_converting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - p(converted) 0.1196 = 11.96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### before answering the question I noticed that the next two question have same answering format so will use function to avoid code replications. \n",
    "- this function will calcualte  p( converted | group_type ) the parmaters will be cloumn1 with type1 and cloumn2 with type2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability (group_type):\n",
    "    return df2[df2['group'] == group_type]['converted'].sum() / df2[df2['group'] == group_type]['converted'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function will return the p( converted | control )\n",
    "probability('control')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - p( converted | control ) = 0.1203 = 12.03 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function will return the p( converted | treatment )\n",
    "probability('treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - p( converted | treatment ) = 0.1188 = 11.88 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will divide the number of total new page by all pages.\n",
    "df2[df2['landing_page'] == 'new_page' ]['user_id'].count()/df2['landing_page'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - p (new_page) = 0.5 = 50 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Consider your results from parts (a) through (d) above, and explain below whether you think there is sufficient evidence to conclude that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**my answer:**\n",
    "if we gather all the probability that we calculated: \n",
    "-  p(converted) 0.1196 = 11.96%\n",
    "-  p( converted | control ) = 0.1203 = 12.03 %\n",
    "-  p( converted | treatment ) = 0.1188 = 11.88 %\n",
    "-  p (new_page) = 0.5 = 50 %\n",
    "\n",
    "##### I would say since we have only 50% of individuals received the new page, running the experiment for longer time needed in order to make a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "\n",
    "`1.` now I will assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, my null and alternative hypotheses be:  \n",
    "\n",
    "**$H_{0}$** : **$p_{old}$** >= **$p_{new}$** ,  \n",
    "**$H_{1}$** : **$p_{old}$** < **$p_{new}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` I will assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, I will assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "- i will use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "- i will perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I assumed that Pnew have \"true\" success rates equal to the converted success rate regardless of page\n",
    "\n",
    "# prob_converting is the converted success rate rate that I calculated earlier \n",
    "p_new = prob_converting\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **conversion rate** for $p_{new}$ under the null = 0.1196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i assumed that Pold have \"true\" success rates equal to the converted success rate regardless of page\n",
    "\n",
    "# prob_converting is the converted success rate rate that I calculated earlier \n",
    "p_old = prob_converting\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **conversion rate** for $p_{old}$ under the null = 0.1196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I create n new data frame that contain all treatment rows \n",
    "n_new = df2[(df2['group'] == 'treatment')]['user_id'].nunique()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the number of individuals in the treatment group $n_{new}$ = 145310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I create n new data frame that contain all control rows \n",
    "n_old = df2[df2['group'] == 'control']['user_id'].nunique()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the number of individuals in the treatment group $n_{new}$ = 145274"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function will generate random array of values 0 or 1 with size of n_new and probability of p_new\n",
    "new_page_converted = np.random.choice([0,1],n_new, p_new)\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function will generate random array of values 0 or 1 with size of n_old and probability of p_old\n",
    "old_page_converted = np.random.choice([0,1],n_old, p_old)\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012183549211989275"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I subtracted the mean of each simulated array to find the difference \n",
    "p_diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "p_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process you used in parts (a) through (g) above. Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the bootstrapping in order to create sampling difference in proportions:\n",
    "\n",
    "# this list will contain all different in proportions \n",
    "p_diffs = []\n",
    "#\n",
    "# for loop of size 10000 each time we will simulate new random array same as above then store it in p_diffs list: \n",
    "#for i in range(10000):\n",
    "#    new_page_converted = np.random.choice([0,1],n_new, p_new)\n",
    "#    old_page_converted = np.random.choice([0,1],n_old, p_old)\n",
    "#    p_diffs.append(new_page_converted.mean() - old_page_converted.mean())\n",
    "#\n",
    "#after the loop ends i will convert the list into numpay array so i can implement numpy method later (.mean())   \n",
    "#p_diffs = np.array(p_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the bluid-in numpy function binomial and it will gives me the same result above with way faster time\n",
    "new_page_converted = np.random.binomial(n_new, p_new, 10000)/n_new\n",
    "old_page_converted = np.random.binomial(n_old, p_old, 10000)/n_old\n",
    "p_diffs = new_page_converted - old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- before i made the plot i will find the acual diffrente to provide it inside the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this new_diff data frame will contain the difference in converted in treatment group\n",
    "new_diff = df2[(df2['converted'] == 1) & (df2['group'] == 'treatment')]['user_id'].count() / df2[df2['group'] == 'treatment']['user_id'].count()\n",
    "\n",
    "# this old_diff data frame will contain the difference in converted in control group\n",
    "old_diff = df2[(df2['converted'] == 1) & (df2['group'] == 'control')]['user_id'].count() / df2[df2['group'] == 'control']['user_id'].count()\n",
    "\n",
    "# I will subtract them to have actual difference in converted between treatment and control group.\n",
    "actual_diff = new_diff - old_diff\n",
    "actual_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here I will plot the sampling distribution\n",
    "plt.hist(p_diffs);\n",
    "\n",
    "# also plot line for observed statistic\n",
    "plt.axvline(x=actual_diff , color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the plot seems as normal disturbation and the actual diffrece is below the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will compute the p value\n",
    "(p_diffs > actual_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. Please explain using the vocabulary you've learned in this course what you just computed in part **j.**  What is this value called in scientific studies?  What does this value mean in terms of whether or not there is a difference between the new and old pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**my answer:**\n",
    "in part j we find the p value and this value will be compared to the error type 1(5%) to determine whether we reject the null hypothesis or fail to reject the null hypothesis: \n",
    "- p-value <= type error 1 in order to reject the null hypothesis\n",
    "   \n",
    "######  but we have 0.9051 > 0.05    so we fail to reject the null hypothesis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# number of conversions for old pages\n",
    "convert_old = df2[(df2['group'] == 'control')&(df2['converted'] == 1)]['user_id'].nunique()\n",
    "\n",
    "# number of conversions for new pages\n",
    "convert_new = df2[(df2['group'] == 'treatment')&(df2['converted'] == 1)]['user_id'].nunique()\n",
    "\n",
    "#number of individuals who received old page\n",
    "n_old = df2[df2['landing_page'] == 'old_page']['user_id'].count()\n",
    "\n",
    "#number of individuals who received new page\n",
    "n_new = df2[df2['landing_page'] == 'new_page']['user_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now I will use `stats.proportions_ztest` to compute your test statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z_score , p_value) = sm.stats.proportions_ztest([convert_new,convert_old] , [n_new,n_old] , alternative='larger')\n",
    "(z_score , p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages?  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z-score gives us how the standard deviations far from the mean witch in our case it is below the mean (negative).  \n",
    "- p-value gives us how data could have occurred under the null hypothesis in our case it support what we find witch fail to     reject the null hypothesis.\n",
    "\n",
    "- yes, they agree with the our findings that we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, we will see that the result you achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will performing logistic regression since we want to predict two chances conversion or no conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the logistic regression model to see if there is a significant difference in conversion based on which page a customer receives. However, first I need to create in df2 a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create intercept column to use it in statsmodels\n",
    "df2['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies method will convert the Categorical values into (1,0) to be able to use it inside the statsmodels\n",
    "# 1 will be for the treatment\n",
    "# 0 will be for the control\n",
    "\n",
    "df2['ab_page']= pd.get_dummies(df2['group'])['treatment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. I will use **statsmodels** to instantiate the logistic regression model, then fit the model using the two columns I created in part **b.** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# I used the statsmodels to predict the conversion \n",
    "lm = sm.Logit(df2['converted'] , df2[['intercept' , 'ab_page']])\n",
    "result = lm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 15 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:57:33</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Tue, 15 Jun 2021   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        09:57:33   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will give me the summary that help me to determine  the p-value associated with ab_page\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with **ab_page**? Why does it differ from the value you found in **Part II**?<br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the p-value associated with ab_page is 0.190 \n",
    "- it is different form what we found in part 2 cause it determine if there     is a difference in conversion based on which page a customer receives   where the part 2 determine if there is a higher conversion based of the new and old pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts.  Discuss why it is a good idea to consider other factors to add into your regression model.  Are there any disadvantages to adding additional terms into your regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need to include other factors such as countries since in previous part we include only the page factor to predict so we can get more accurate result whether we reject the null hypothesis or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. I will need to read in the **countries.csv** dataset and merge together your datasets on the appropriate rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the countries file \n",
    "countries = pd.read_csv('countries.csv')\n",
    "countries.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290584 entries, 0 to 290583\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   user_id  290584 non-null  int64 \n",
      " 1   country  290584 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# I will see some information about the dataset\n",
    "countries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp    group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739  control     old_page          0   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I will create a new data frame joined_df that contain the two data frames df2 and countries the will be merged on user id\n",
    "\n",
    "joined_df = df2.merge(countries , on=['user_id'] , how='inner')\n",
    "joined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  CA  UK  US  \n",
       "0          1        0      US   0   0   1  \n",
       "1          1        0      US   0   0   1  \n",
       "2          1        1      US   0   0   1  \n",
       "3          1        1      US   0   0   1  \n",
       "4          1        0      US   0   0   1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use get dummies to convert the categorical data so I can use them in model\n",
    "\n",
    "joined_df[['CA', 'UK', 'US']] = pd.get_dummies(joined_df['country'])\n",
    "joined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though I have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.I will create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "I will Provide the summary results, and my conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 15 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:57:54</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0300</td> <td>    0.027</td> <td>  -76.249</td> <td> 0.000</td> <td>   -2.082</td> <td>   -1.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0408</td> <td>    0.027</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.012</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0506</td> <td>    0.028</td> <td>    1.784</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.106</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 15 Jun 2021   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        09:57:54   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0300      0.027    -76.249      0.000      -2.082      -1.978\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "US             0.0408      0.027      1.516      0.130      -0.012       0.093\n",
       "UK             0.0506      0.028      1.784      0.074      -0.005       0.106\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use the statsmodels to predict the conversion and show the summary\n",
    "\n",
    "joined_df['intercept'] = 1\n",
    "lm = sm.Logit(joined_df['converted'], joined_df[['intercept', 'ab_page', 'US', 'UK']])\n",
    "results = lm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### - it seems with including the country factor in conversion form new and old pages didn’t affect them.\n",
    "\n",
    "#### - the p-value associated with ab_page doesn’t change  from the last model = 0.191 and it is bigger than type 1 error 0.05 so we fail to reject the  null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to find if there is an interaction between page and country to see if there significant effects on conversion. so you need to create additional interaction columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['US_ab_page'] = joined_df['US'] * joined_df['ab_page']\n",
    "joined_df['CA_ab_page'] = joined_df['CA'] * joined_df['ab_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 15 Jun 2021</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:02:31</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -2.0040</td> <td>    0.036</td> <td>  -55.008</td> <td> 0.000</td> <td>   -2.075</td> <td>   -1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>    0.0108</td> <td>    0.023</td> <td>    0.475</td> <td> 0.635</td> <td>   -0.034</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>         <td>    0.0175</td> <td>    0.038</td> <td>    0.465</td> <td> 0.642</td> <td>   -0.056</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>         <td>    0.0118</td> <td>    0.040</td> <td>    0.296</td> <td> 0.767</td> <td>   -0.066</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US_ab_page</th> <td>   -0.0314</td> <td>    0.027</td> <td>   -1.181</td> <td> 0.238</td> <td>   -0.084</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_ab_page</th> <td>   -0.0783</td> <td>    0.057</td> <td>   -1.378</td> <td> 0.168</td> <td>   -0.190</td> <td>    0.033</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 15 Jun 2021   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        10:02:31   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0040      0.036    -55.008      0.000      -2.075      -1.933\n",
       "ab_page        0.0108      0.023      0.475      0.635      -0.034       0.056\n",
       "US             0.0175      0.038      0.465      0.642      -0.056       0.091\n",
       "UK             0.0118      0.040      0.296      0.767      -0.066       0.090\n",
       "US_ab_page    -0.0314      0.027     -1.181      0.238      -0.084       0.021\n",
       "CA_ab_page    -0.0783      0.057     -1.378      0.168      -0.190       0.033\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the two new cloumns in the model \n",
    "lm = sm.Logit(joined_df['converted'], joined_df[['intercept', 'ab_page', 'US', 'UK' , 'US_ab_page' , 'CA_ab_page']])\n",
    "results = lm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since all factors except (intercept) have no significant effects on conversion (p-value > 0.05) I can say that countries have no significant effects on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "\n",
    "# Conclusions:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 : \n",
    "###### given the probability that we found specially the probability of individuals received a new page, we need to run the experiment for   longer time in order to make a decision.\n",
    "-  p(converted) 0.1196 = 11.96%\n",
    "-  p( converted | control ) = 0.1203 = 12.03 %\n",
    "-  p( converted | treatment ) = 0.1188 = 11.88 %\n",
    "-  p (new_page) = 0.5 = 50 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 :  \n",
    "######  bead on the p-value we found and the given type of error 1 we fail to reject the null hypothesis \n",
    "- p-value <= type error 1 in order to reject the null hypothesis \n",
    "######  but we have 0.9051 >  0.05   so we fail to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part III - A regression approach : \n",
    "- the p-value associated with ab_page is 0.190 \n",
    "- even with including other factor (countries) the p-value associated with ab_page doesnt got affected.\n",
    "- the p-value associated with ab_page doesn’t change  from the last model = 0.191 and it is bigger than type 1 error 0.05 so we **fail to reject the  null hypothesis**.\n",
    "- countries have no significant effects on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally,\n",
    "my decision regarding this A/B test, we fail to reject the null hypothesis so I recommend the company to keep the old page and dont switch to the new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
